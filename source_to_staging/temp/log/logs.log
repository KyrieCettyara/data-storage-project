2025-02-24 22:32:02,903 - INFO - ==================================STARTING EXTRACT DATA=======================================
2025-02-24 22:32:03,176 - INFO - EXTRACT 'address' - SUCCESS.
2025-02-24 22:32:03,206 - INFO - EXTRACT 'address_status' - SUCCESS.
2025-02-24 22:32:03,306 - INFO - EXTRACT 'author' - SUCCESS.
2025-02-24 22:32:03,406 - INFO - EXTRACT 'book_author' - SUCCESS.
2025-02-24 22:32:03,428 - INFO - EXTRACT 'book_language' - SUCCESS.
2025-02-24 22:32:03,688 - INFO - EXTRACT 'book' - SUCCESS.
2025-02-24 22:32:03,715 - INFO - EXTRACT 'country' - SUCCESS.
2025-02-24 22:32:03,853 - INFO - EXTRACT 'cust_order' - SUCCESS.
2025-02-24 22:32:03,884 - INFO - EXTRACT 'customer_address' - SUCCESS.
2025-02-24 22:32:03,911 - INFO - EXTRACT 'customer' - SUCCESS.
2025-02-24 22:32:04,173 - INFO - EXTRACT 'order_history' - SUCCESS.
2025-02-24 22:32:04,327 - INFO - EXTRACT 'order_line' - SUCCESS.
2025-02-24 22:32:04,345 - INFO - EXTRACT 'order_status' - SUCCESS.
2025-02-24 22:32:04,383 - INFO - EXTRACT 'publisher' - SUCCESS.
2025-02-24 22:32:04,408 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2025-02-24 22:32:04,409 - INFO - Extract All Tables From Sources - SUCCESS
2025-02-24 22:32:04,424 - INFO - ==================================ENDING EXTRACT DATA=======================================
2025-02-24 22:32:04,425 - INFO - [pid 6400] Worker Worker(salt=1575883089, workers=1, host=KyrieEl, username=kyrie, pid=6400) done      Extract()
2025-02-24 22:32:04,428 - DEBUG - 1 running tasks, waiting for next task to finish
2025-02-24 22:32:04,434 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2025-02-24 22:32:04,435 - DEBUG - Asking scheduler for work...
2025-02-24 22:32:04,441 - DEBUG - Pending tasks: 1
2025-02-24 22:32:04,443 - INFO - [pid 6400] Worker Worker(salt=1575883089, workers=1, host=KyrieEl, username=kyrie, pid=6400) running   Load()
2025-02-24 22:32:04,486 - INFO - ==================================STARTING TRUNCATE=======================================
2025-02-24 22:32:04,522 - INFO - TRUNCATE address - SUCCESS
2025-02-24 22:32:04,530 - INFO - TRUNCATE address_status - SUCCESS
2025-02-24 22:32:04,541 - INFO - TRUNCATE author - SUCCESS
2025-02-24 22:32:04,548 - INFO - TRUNCATE book_author - SUCCESS
2025-02-24 22:32:04,556 - INFO - TRUNCATE book_language - SUCCESS
2025-02-24 22:32:04,564 - INFO - TRUNCATE book - SUCCESS
2025-02-24 22:32:04,574 - INFO - TRUNCATE country - SUCCESS
2025-02-24 22:32:04,582 - INFO - TRUNCATE cust_order - SUCCESS
2025-02-24 22:32:04,591 - INFO - TRUNCATE customer_address - SUCCESS
2025-02-24 22:32:04,606 - INFO - TRUNCATE customer - SUCCESS
2025-02-24 22:32:04,615 - INFO - TRUNCATE order_history - SUCCESS
2025-02-24 22:32:04,623 - INFO - TRUNCATE order_line - SUCCESS
2025-02-24 22:32:04,631 - INFO - TRUNCATE order_status - SUCCESS
2025-02-24 22:32:04,639 - INFO - TRUNCATE publisher - SUCCESS
2025-02-24 22:32:04,650 - INFO - TRUNCATE shipping_method - SUCCESS
2025-02-24 22:32:04,651 - INFO - TRUNCATE ALL TABLES - DONE
2025-02-24 22:32:04,652 - INFO - ==================================END TRUNCATE=======================================
2025-02-24 22:32:04,652 - INFO - ==================================STARTING LOAD DATA=================================
2025-02-24 22:32:04,730 - INFO - READ 'address' - SUCCESS
2025-02-24 22:32:04,749 - INFO - READ 'address_status' - SUCCESS
2025-02-24 22:32:04,766 - INFO - READ 'author' - SUCCESS
2025-02-24 22:32:04,780 - INFO - READ 'book_author' - SUCCESS
2025-02-24 22:32:04,790 - INFO - READ 'book_language' - SUCCESS
2025-02-24 22:32:04,827 - INFO - READ 'book' - SUCCESS
2025-02-24 22:32:04,841 - INFO - READ 'country' - SUCCESS
2025-02-24 22:32:04,861 - INFO - READ 'cust_order' - SUCCESS
2025-02-24 22:32:04,874 - INFO - READ 'customer_address' - SUCCESS
2025-02-24 22:32:04,887 - INFO - READ 'customer' - SUCCESS
2025-02-24 22:32:04,924 - INFO - READ 'order_history' - SUCCESS
2025-02-24 22:32:04,953 - INFO - READ 'order_line' - SUCCESS
2025-02-24 22:32:04,968 - INFO - READ 'order_status' - SUCCESS
2025-02-24 22:32:04,984 - INFO - READ 'publisher' - SUCCESS
2025-02-24 22:32:04,996 - INFO - READ 'shipping_method' - SUCCESS
2025-02-24 22:32:04,999 - INFO - READ EXTRACTED TABLES - SUCCESS
2025-02-24 22:32:05,046 - INFO - LOAD 'address' - SUCCESS
2025-02-24 22:32:05,057 - INFO - LOAD 'address_status' - SUCCESS
2025-02-24 22:32:05,259 - INFO - LOAD 'author' - SUCCESS
2025-02-24 22:32:05,521 - INFO - LOAD 'book_author' - SUCCESS
2025-02-24 22:32:05,531 - INFO - LOAD 'book_language' - SUCCESS
2025-02-24 22:32:06,328 - INFO - LOAD 'book' - SUCCESS
2025-02-24 22:32:06,347 - INFO - LOAD 'country' - SUCCESS
2025-02-24 22:32:06,578 - INFO - LOAD 'cust_order' - SUCCESS
2025-02-24 22:32:06,686 - INFO - LOAD 'customer_address' - SUCCESS
2025-02-24 22:32:06,798 - INFO - LOAD 'customer' - SUCCESS
2025-02-24 22:32:07,468 - INFO - LOAD 'order_history' - SUCCESS
2025-02-24 22:32:08,074 - INFO - LOAD 'order_line' - SUCCESS
2025-02-24 22:32:08,091 - INFO - LOAD 'order_status' - SUCCESS
2025-02-24 22:32:08,162 - INFO - LOAD 'publisher' - SUCCESS
2025-02-24 22:32:08,180 - INFO - LOAD 'shipping_method' - SUCCESS
2025-02-24 22:32:08,181 - INFO - LOAD ALL DATA - SUCCESS
2025-02-24 22:32:08,197 - INFO - ==================================ENDING LOAD DATA=======================================
2025-02-24 22:32:08,201 - INFO - [pid 6400] Worker Worker(salt=1575883089, workers=1, host=KyrieEl, username=kyrie, pid=6400) done      Load()
2025-02-24 22:32:08,204 - DEBUG - 1 running tasks, waiting for next task to finish
2025-02-24 22:32:08,214 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2025-02-24 22:32:08,215 - DEBUG - Asking scheduler for work...
2025-02-24 22:32:08,224 - DEBUG - Done
2025-02-24 22:32:08,225 - DEBUG - There are no more tasks to run at this time
2025-02-24 22:32:08,229 - INFO - Worker Worker(salt=1575883089, workers=1, host=KyrieEl, username=kyrie, pid=6400) was stopped. Shutting down Keep-Alive thread
2025-02-24 22:32:08,233 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2025-02-24 23:34:33,963 - INFO - ==================================STARTING EXTRACT DATA=======================================
2025-02-24 23:34:34,338 - INFO - EXTRACT 'address' - SUCCESS.
2025-02-24 23:34:34,352 - INFO - EXTRACT 'address_status' - SUCCESS.
2025-02-24 23:34:34,407 - INFO - EXTRACT 'author' - SUCCESS.
2025-02-24 23:34:34,476 - INFO - EXTRACT 'book_author' - SUCCESS.
2025-02-24 23:34:34,489 - INFO - EXTRACT 'book_language' - SUCCESS.
2025-02-24 23:34:34,613 - INFO - EXTRACT 'book' - SUCCESS.
2025-02-24 23:34:34,630 - INFO - EXTRACT 'country' - SUCCESS.
2025-02-24 23:34:34,780 - INFO - EXTRACT 'cust_order' - SUCCESS.
2025-02-24 23:34:34,813 - INFO - EXTRACT 'customer_address' - SUCCESS.
2025-02-24 23:34:34,839 - INFO - EXTRACT 'customer' - SUCCESS.
2025-02-24 23:34:35,064 - INFO - EXTRACT 'order_history' - SUCCESS.
2025-02-24 23:34:35,151 - INFO - EXTRACT 'order_line' - SUCCESS.
2025-02-24 23:34:35,164 - INFO - EXTRACT 'order_status' - SUCCESS.
2025-02-24 23:34:35,185 - INFO - EXTRACT 'publisher' - SUCCESS.
2025-02-24 23:34:35,200 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2025-02-24 23:34:35,201 - INFO - Extract All Tables From Sources - SUCCESS
2025-02-24 23:34:35,211 - INFO - ==================================ENDING EXTRACT DATA=======================================
2025-02-24 23:34:35,212 - INFO - [pid 21282] Worker Worker(salt=5525446219, workers=1, host=KyrieEl, username=kyrie, pid=21282) done      Extract()
2025-02-24 23:34:35,213 - DEBUG - 1 running tasks, waiting for next task to finish
2025-02-24 23:34:35,217 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2025-02-24 23:34:35,218 - DEBUG - Asking scheduler for work...
2025-02-24 23:34:35,224 - DEBUG - Pending tasks: 1
2025-02-24 23:34:35,226 - INFO - [pid 21282] Worker Worker(salt=5525446219, workers=1, host=KyrieEl, username=kyrie, pid=21282) running   Load()
2025-02-24 23:34:35,261 - INFO - ==================================STARTING TRUNCATE=======================================
2025-02-24 23:34:35,732 - ERROR - TRUNCATE DATA - FAILED: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5435 failed: FATAL:  database "pacbook_staging" does not exist

(Background on this error at: https://sqlalche.me/e/20/e3q8)
Traceback (most recent call last):
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5435 failed: FATAL:  database "pacbook_staging" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/source_to_staging/pipeline/load.py", line 56, in run
    with trg_engine.connect() as conn:
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5435 failed: FATAL:  database "pacbook_staging" does not exist

(Background on this error at: https://sqlalche.me/e/20/e3q8)

2025-02-24 23:34:35,733 - ERROR - [pid 21282] Worker Worker(salt=5525446219, workers=1, host=KyrieEl, username=kyrie, pid=21282) failed    Load()
Traceback (most recent call last):
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5435 failed: FATAL:  database "pacbook_staging" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/source_to_staging/pipeline/load.py", line 56, in run
    with trg_engine.connect() as conn:
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5435 failed: FATAL:  database "pacbook_staging" does not exist

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/.venv/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Kyrie/Pacmann/DataStorageManagement/Project/data-storage-project/source_to_staging/pipeline/load.py", line 76, in run
    raise Exception("Failed to truncate data")
Exception: Failed to truncate data
2025-02-24 23:34:35,851 - DEBUG - 1 running tasks, waiting for next task to finish
2025-02-24 23:34:35,870 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2025-02-24 23:34:35,871 - DEBUG - Asking scheduler for work...
2025-02-24 23:34:35,877 - DEBUG - Done
2025-02-24 23:34:35,877 - DEBUG - There are no more tasks to run at this time
2025-02-24 23:34:35,878 - DEBUG - There are 1 pending tasks possibly being run by other workers
2025-02-24 23:34:35,879 - DEBUG - There are 1 pending tasks unique to this worker
2025-02-24 23:34:35,880 - DEBUG - There are 1 pending tasks last scheduled by this worker
2025-02-24 23:34:35,882 - INFO - Worker Worker(salt=5525446219, workers=1, host=KyrieEl, username=kyrie, pid=21282) was stopped. Shutting down Keep-Alive thread
2025-02-24 23:34:35,885 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2025-02-24 23:35:22,376 - INFO - ==================================STARTING EXTRACT DATA=======================================
2025-02-24 23:35:22,566 - INFO - EXTRACT 'address' - SUCCESS.
2025-02-24 23:35:22,580 - INFO - EXTRACT 'address_status' - SUCCESS.
2025-02-24 23:35:22,620 - INFO - EXTRACT 'author' - SUCCESS.
2025-02-24 23:35:22,673 - INFO - EXTRACT 'book_author' - SUCCESS.
2025-02-24 23:35:22,687 - INFO - EXTRACT 'book_language' - SUCCESS.
2025-02-24 23:35:22,804 - INFO - EXTRACT 'book' - SUCCESS.
2025-02-24 23:35:22,822 - INFO - EXTRACT 'country' - SUCCESS.
2025-02-24 23:35:22,945 - INFO - EXTRACT 'cust_order' - SUCCESS.
2025-02-24 23:35:22,974 - INFO - EXTRACT 'customer_address' - SUCCESS.
2025-02-24 23:35:23,000 - INFO - EXTRACT 'customer' - SUCCESS.
2025-02-24 23:35:23,167 - INFO - EXTRACT 'order_history' - SUCCESS.
2025-02-24 23:35:23,268 - INFO - EXTRACT 'order_line' - SUCCESS.
2025-02-24 23:35:23,280 - INFO - EXTRACT 'order_status' - SUCCESS.
2025-02-24 23:35:23,315 - INFO - EXTRACT 'publisher' - SUCCESS.
2025-02-24 23:35:23,328 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2025-02-24 23:35:23,329 - INFO - Extract All Tables From Sources - SUCCESS
2025-02-24 23:35:23,340 - INFO - ==================================ENDING EXTRACT DATA=======================================
2025-02-24 23:35:23,341 - INFO - [pid 21499] Worker Worker(salt=4041575530, workers=1, host=KyrieEl, username=kyrie, pid=21499) done      Extract()
2025-02-24 23:35:23,342 - DEBUG - 1 running tasks, waiting for next task to finish
2025-02-24 23:35:23,348 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2025-02-24 23:35:23,350 - DEBUG - Asking scheduler for work...
2025-02-24 23:35:23,356 - DEBUG - Pending tasks: 1
2025-02-24 23:35:23,357 - INFO - [pid 21499] Worker Worker(salt=4041575530, workers=1, host=KyrieEl, username=kyrie, pid=21499) running   Load()
2025-02-24 23:35:23,397 - INFO - ==================================STARTING TRUNCATE=======================================
2025-02-24 23:35:23,437 - INFO - TRUNCATE address - SUCCESS
2025-02-24 23:35:23,448 - INFO - TRUNCATE address_status - SUCCESS
2025-02-24 23:35:23,458 - INFO - TRUNCATE author - SUCCESS
2025-02-24 23:35:23,467 - INFO - TRUNCATE book_author - SUCCESS
2025-02-24 23:35:23,475 - INFO - TRUNCATE book_language - SUCCESS
2025-02-24 23:35:23,483 - INFO - TRUNCATE book - SUCCESS
2025-02-24 23:35:23,492 - INFO - TRUNCATE country - SUCCESS
2025-02-24 23:35:23,499 - INFO - TRUNCATE cust_order - SUCCESS
2025-02-24 23:35:23,508 - INFO - TRUNCATE customer_address - SUCCESS
2025-02-24 23:35:23,519 - INFO - TRUNCATE customer - SUCCESS
2025-02-24 23:35:23,527 - INFO - TRUNCATE order_history - SUCCESS
2025-02-24 23:35:23,533 - INFO - TRUNCATE order_line - SUCCESS
2025-02-24 23:35:23,540 - INFO - TRUNCATE order_status - SUCCESS
2025-02-24 23:35:23,546 - INFO - TRUNCATE publisher - SUCCESS
2025-02-24 23:35:23,555 - INFO - TRUNCATE shipping_method - SUCCESS
2025-02-24 23:35:23,555 - INFO - TRUNCATE ALL TABLES - DONE
2025-02-24 23:35:23,556 - INFO - ==================================END TRUNCATE=======================================
2025-02-24 23:35:23,557 - INFO - ==================================STARTING LOAD DATA=================================
2025-02-24 23:35:23,627 - INFO - READ 'address' - SUCCESS
2025-02-24 23:35:23,662 - INFO - READ 'address_status' - SUCCESS
2025-02-24 23:35:23,679 - INFO - READ 'author' - SUCCESS
2025-02-24 23:35:23,692 - INFO - READ 'book_author' - SUCCESS
2025-02-24 23:35:23,702 - INFO - READ 'book_language' - SUCCESS
2025-02-24 23:35:23,735 - INFO - READ 'book' - SUCCESS
2025-02-24 23:35:23,745 - INFO - READ 'country' - SUCCESS
2025-02-24 23:35:23,766 - INFO - READ 'cust_order' - SUCCESS
2025-02-24 23:35:23,776 - INFO - READ 'customer_address' - SUCCESS
2025-02-24 23:35:23,791 - INFO - READ 'customer' - SUCCESS
2025-02-24 23:35:23,820 - INFO - READ 'order_history' - SUCCESS
2025-02-24 23:35:23,837 - INFO - READ 'order_line' - SUCCESS
2025-02-24 23:35:23,848 - INFO - READ 'order_status' - SUCCESS
2025-02-24 23:35:23,861 - INFO - READ 'publisher' - SUCCESS
2025-02-24 23:35:23,872 - INFO - READ 'shipping_method' - SUCCESS
2025-02-24 23:35:23,873 - INFO - READ EXTRACTED TABLES - SUCCESS
2025-02-24 23:35:23,950 - INFO - LOAD 'address' - SUCCESS
2025-02-24 23:35:23,962 - INFO - LOAD 'address_status' - SUCCESS
2025-02-24 23:35:24,091 - INFO - LOAD 'author' - SUCCESS
2025-02-24 23:35:24,294 - INFO - LOAD 'book_author' - SUCCESS
2025-02-24 23:35:24,304 - INFO - LOAD 'book_language' - SUCCESS
2025-02-24 23:35:24,743 - INFO - LOAD 'book' - SUCCESS
2025-02-24 23:35:24,758 - INFO - LOAD 'country' - SUCCESS
2025-02-24 23:35:24,919 - INFO - LOAD 'cust_order' - SUCCESS
2025-02-24 23:35:24,987 - INFO - LOAD 'customer_address' - SUCCESS
2025-02-24 23:35:25,031 - INFO - LOAD 'customer' - SUCCESS
2025-02-24 23:35:25,495 - INFO - LOAD 'order_history' - SUCCESS
2025-02-24 23:35:25,847 - INFO - LOAD 'order_line' - SUCCESS
2025-02-24 23:35:25,858 - INFO - LOAD 'order_status' - SUCCESS
2025-02-24 23:35:25,897 - INFO - LOAD 'publisher' - SUCCESS
2025-02-24 23:35:25,906 - INFO - LOAD 'shipping_method' - SUCCESS
2025-02-24 23:35:25,907 - INFO - LOAD ALL DATA - SUCCESS
2025-02-24 23:35:25,916 - INFO - ==================================ENDING LOAD DATA=======================================
2025-02-24 23:35:25,919 - INFO - [pid 21499] Worker Worker(salt=4041575530, workers=1, host=KyrieEl, username=kyrie, pid=21499) done      Load()
2025-02-24 23:35:25,920 - DEBUG - 1 running tasks, waiting for next task to finish
2025-02-24 23:35:25,926 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2025-02-24 23:35:25,927 - DEBUG - Asking scheduler for work...
2025-02-24 23:35:25,934 - DEBUG - Done
2025-02-24 23:35:25,935 - DEBUG - There are no more tasks to run at this time
2025-02-24 23:35:25,936 - INFO - Worker Worker(salt=4041575530, workers=1, host=KyrieEl, username=kyrie, pid=21499) was stopped. Shutting down Keep-Alive thread
2025-02-24 23:35:25,937 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

